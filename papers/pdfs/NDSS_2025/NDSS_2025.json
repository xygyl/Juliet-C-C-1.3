[
  {
    "file_name": "A Preliminary Study on Using Large Language.pdf",
    "bug_type": "The bug types discussed in the paper include vulnerabilities such as SQL injection, cross-site scripting, weak hashing algorithms, and others. These vulnerabilities are considered real-world as they are common security issues found in software applications.",
    "bug_origin": "Real-world",
    "programming_language": "The programming language used in the benchmarks is Java.",
    "benchmarks_or_datasets": "The benchmarks used in the study are from the OWASP Benchmark Project, which contains 2740 Java programs with various vulnerabilities.",
    "dataset_tool_repo": "The context does not provide a specific link to a dataset/tool repository.",
    "publicly_available": "No",
    "llm_prompt_strategy": ""
  },
  {
    "file_name": "Towards LLM-Assisted Vulnerability Detection and.pdf",
    "bug_type": "",
    "bug_origin": "Unknown",
    "programming_language": "",
    "benchmarks_or_datasets": "",
    "dataset_tool_repo": "",
    "publicly_available": "No",
    "llm_prompt_strategy": ""
  },
  {
    "file_name": "Automated Static Vulnerability Detection via a Holistic Neuro-symbolic Approach.pdf",
    "bug_type": "The bug types examined in the paper include seven types of vulnerabilities from the OWASP Top Ten, specifically in PHP and JavaScript. The vulnerabilities are real-world, as they are derived from known vulnerabilities in popular projects.",
    "bug_origin": "Real-world",
    "programming_language": "The programming languages used in the study are PHP and JavaScript.",
    "benchmarks_or_datasets": "The evaluation used two datasets:",
    "dataset_tool_repo": "The paper does not explicitly mention a link to a dataset or tool repository. Therefore, it is unclear if such a repository is provided.",
    "publicly_available": "No",
    "llm_prompt_strategy": "Yes, the paper mentions the use of several prompting strategies for LLMs, including:"
  },
  {
    "file_name": "PropertyGPT_ LLM-driven Formal Verification of.pdf",
    "bug_type": "The bug types discussed in the paper include vulnerabilities such as integer overflow, re-entrancy, front-running, and access control vulnerabilities. These vulnerabilities are real-world issues that have been identified in smart contracts.",
    "bug_origin": "Real-world",
    "programming_language": "The programming language used is Solidity, which is commonly used for writing smart contracts on blockchain platforms like Ethereum.",
    "benchmarks_or_datasets": "The paper utilizes a dataset of 623 human-written properties collected from 23 Certora projects. Additionally, it evaluates PropertyGPT against 13 CVEs (Common Vulnerabilities and Exposures) and 24 attack incident projects from the SmartInv benchmark.",
    "dataset_tool_repo": "Yes, a dataset/tool repository is provided. The link is: [https://github.com/Pr0pertyGPT/PropertyGPT](https://github.com/Pr0pertyGPT/PropertyGPT).",
    "publicly_available": "Yes",
    "llm_prompt_strategy": ""
  },
  {
    "file_name": "YURASCANNER_ Leveraging LLMs for.pdf",
    "bug_type": "The bug type discussed in the paper primarily focuses on real-world vulnerabilities, specifically cross-site scripting (XSS) vulnerabilities.",
    "bug_origin": "Real-world",
    "programming_language": "The programming language used for implementing YURASCANNER is JavaScript (Node.js).",
    "benchmarks_or_datasets": "The evaluation of YURASCANNER is conducted against 20 real and diverse web applications, with a focus on two datasets: TE (Task Execution) dataset and TE+VD (Task Execution + Vulnerability Detection) dataset.",
    "dataset_tool_repo": "The paper mentions that artifacts, including Docker files and configuration, will be shared, but the source code of YURASCANNER will not be publicly available. Instead, interested researchers can apply for access through a submission form. The specific link to the submission form is not provided in the context.",
    "publicly_available": "No",
    "llm_prompt_strategy": ""
  },
  {
    "file_name": "Large Language Model guided Protocol Fuzzing.pdf",
    "bug_type": "The bugs discovered are real-world vulnerabilities, including memory vulnerabilities such as use-after-free, buffer overflow, and memory leaks.",
    "bug_origin": "Real-world",
    "programming_language": "The tool is designed to test protocols written in C/C++.",
    "benchmarks_or_datasets": "The benchmarks used include the PRO-FUZZBENCH protocol fuzzer benchmark, which comprises a suite of representative open-source network servers for popular protocols.",
    "dataset_tool_repo": "Yes, the tool is publicly available at the following link: [CHATAFL GitHub Repository](https://github.com/ChatAFLndss/ChatAFL).",
    "publicly_available": "Yes",
    "llm_prompt_strategy": ""
  },
  {
    "file_name": "The Midas Touch_ Triggering the Capability of.pdf",
    "bug_type": "The bug type is related to resource-management API misuse, specifically focusing on security issues such as memory leaks, use-after-free, and double-free bugs. These are real-world bugs found in applications integrating popular libraries.",
    "bug_origin": "Real-world",
    "programming_language": "The programming language used is C, as indicated by the context discussing libraries like FFmpeg, Libevent, Libzip, and others, which are commonly associated with C programming.",
    "benchmarks_or_datasets": "The benchmarks or datasets used include:",
    "dataset_tool_repo": "The provided text does not mention a specific dataset or tool repository link. Therefore, it appears that no direct link is provided in the context.",
    "publicly_available": "No",
    "llm_prompt_strategy": "Yes, the paper describes a two-dimensional prompting approach for cross-validation and an inconsistency-checking approach between the LLMs' output and the reasoning process. It also mentions utilizing the ReAct framework and Chain-of-Thought (CoT) techniques to enhance the reasoning capabilities of the LLMs in identifying resource-management APIs."
  },
  {
    "file_name": "Enhancing Security in Third-Party Library Reuse -.pdf",
    "bug_type": "The bug type discussed in the paper is \"1-day vulnerabilities\" introduced through the reuse of third-party libraries (TPLs). These vulnerabilities are real-world vulnerabilities.",
    "bug_origin": "Real-world",
    "programming_language": "The programming languages mentioned in the context of the paper are C and C++.",
    "benchmarks_or_datasets": "The paper mentions a benchmark created by manually analyzing 68 real-world projects, labeling 200 TPL reuses, and identifying 200 vulnerable reused functions from those reuses. Additionally, a database named DB_iot containing 1,872 IoT-specific TPLs is constructed for evaluation.",
    "dataset_tool_repo": "The text does not provide a specific link to a dataset or tool repository. It mentions the construction of a database (DB_iot) but does not indicate that it is publicly available.",
    "publicly_available": "No",
    "llm_prompt_strategy": "Yes, the paper describes the use of an LLM (specifically GPT-3.5 and GPT-4.0) for various tasks, including parsing vulnerability descriptions, extracting vulnerable elements, and confirming patch commits. The LLM is employed to enhance the accuracy of identifying vulnerabilities and patches based on natural language descriptions."
  },
  {
    "file_name": "From Large to Mammoth_ A Comparative Evaluation of Large Language.pdf",
    "bug_type": "The bug types evaluated in the study are real-world vulnerabilities, specifically in Java and C/C++ code. The datasets used include known vulnerabilities from open-source projects.",
    "bug_origin": "Real-world",
    "programming_language": "The programming languages used in the study are Java and C/C++.",
    "benchmarks_or_datasets": "The benchmarks/datasets used include:",
    "dataset_tool_repo": "Yes, the paper mentions that all derived datasets, model parameters, configurations, and raw results will be released in the public domain upon the end of the review process. However, a specific link is not provided in the context.",
    "publicly_available": "No",
    "llm_prompt_strategy": "The study employs a **zero-shot prompting strategy** to evaluate the models' inherent capabilities in vulnerability detection without task-specific fine-tuning or examples. Additionally, a **few-shot learning approach** is also tested, where examples of vulnerable and non-vulnerable code are included in the prompt to assess the models' performance."
  }
]