[
  {
    "file_name": "On Evaluating the Efficiency of Source Code Generated by LLMs.pdf",
    "bug_type": "The paper does not explicitly mention specific bug types. However, it evaluates the efficiency of code generated by LLMs, focusing on functional correctness and execution efficiency rather than specific bugs. The bugs can be inferred to be related to performance inefficiencies rather than traditional bugs, and they are likely synthetic as they are generated through LLMs.",
    "bug_origin": "Synthetic",
    "programming_language": "The primary programming language used in the benchmarks is Python for HumanEval and MBPP. Additionally, C++ is used for the LeetCodeEval benchmark.",
    "benchmarks_or_datasets": "The benchmarks/datasets used are:",
    "dataset_tool_repo": "Yes, the paper mentions that code, data, and other artifacts are made available online, but it does not provide a specific link in the provided context.",
    "publicly_available": "No",
    "llm_prompt_strategy": "Yes, the paper describes three different prompt strategies:"
  },
  {
    "file_name": "Prompt-Enhanced Software Vulnerability Detection Using ChatGPT.pdf",
    "bug_type": "The bug types include both synthetic and real-world vulnerabilities. The datasets used contain real-world vulnerable samples as well as synthetic test cases.",
    "bug_origin": "Real-world",
    "programming_language": "The programming languages used in the study are Java and C/C++.",
    "benchmarks_or_datasets": "The datasets used are:",
    "dataset_tool_repo": "The paper does not explicitly provide a link to a dataset/tool repository in the provided text.",
    "publicly_available": "No",
    "llm_prompt_strategy": "Yes, various prompt strategies are used, including:"
  },
  {
    "file_name": "Coca_ Improving and Explaining Graph Neural Network-Based Vulnerability Detection Systems.pdf",
    "bug_type": "The bug types discussed in the paper are vulnerabilities, which are considered real-world bugs. The dataset used for evaluation comprises well-labeled programs extracted from real-world mainstream projects.",
    "bug_origin": "Real-world",
    "programming_language": "The programming languages mentioned in the context are C and C++.",
    "benchmarks_or_datasets": "The benchmarks or datasets used include:",
    "dataset_tool_repo": "The context does not provide a specific link to a dataset/tool repository. However, it mentions that the datasets are collected from real-world projects.",
    "publicly_available": "No",
    "llm_prompt_strategy": "The context does not explicitly mention the use of any LLM (Large Language Model) prompt strategy."
  },
  {
    "file_name": "Investigating the Efficacy of Large Language Models for Code Clone Detection.pdf",
    "bug_type": "The bug type discussed in the paper pertains to Type-4 code clones, which are challenging to detect due to their different syntactic variants while sharing the same functionality. The paper does not explicitly state whether the clones are synthetic or real-world, but it uses a dataset derived from CodeNet, which includes real-world coding problems.",
    "bug_origin": "Real-world",
    "programming_language": "The programming languages used in the study are Java and Ruby.",
    "benchmarks_or_datasets": "The benchmarks or datasets used include the Project CodeNet dataset, which contains 14 million code samples from 4,000 coding problems in over 50 languages. The specific datasets sampled for the study are Java-Java (CCD JJ) and Java-Ruby (XCCD JR) pairs.",
    "dataset_tool_repo": "Yes, a tool repository is mentioned in the context of CodeNet, but the specific link is not provided in the text you shared. You may need to refer to the original paper for the exact link.",
    "publicly_available": "Yes",
    "llm_prompt_strategy": "Yes, the paper discusses a prompt design strategy where ChatGPT is asked to evaluate whether two code snippets solve the same problem with the same inputs and outputs. The final prompt format is:"
  },
  {
    "file_name": "GPTScan_ Detecting Logic Vulnerabilities in Smart Contracts by Combining GPT with Program Analysis.pdf",
    "bug_type": "The bug types discussed in the paper are logic vulnerabilities in smart contracts, which are primarily real-world vulnerabilities. The paper mentions specific types such as price manipulation, ID-related violations, erroneous state updates, atomicity violation, privilege escalation, and erroneous accounting.",
    "bug_origin": "Real-world",
    "programming_language": "The programming language used for the smart contracts is Solidity.",
    "benchmarks_or_datasets": "The paper uses three datasets for evaluation:",
    "dataset_tool_repo": "Yes, the evaluation data for GPTScan is available at [https://sites.google.com/view/gptscan](https://sites.google.com/view/gptscan).",
    "publicly_available": "Yes",
    "llm_prompt_strategy": ""
  },
  {
    "file_name": "Prompting Is All Your Need_ Automated Android Bug Replay with Large Language Models.pdf",
    "bug_type": "The bugs are real-world bugs, as the paper discusses the evaluation of the proposed approach using real-world bug reports collected from various sources.",
    "bug_origin": "Real-world",
    "programming_language": "The programming language used is Java, as it is commonly associated with Android app development.",
    "benchmarks_or_datasets": "The benchmarks or datasets used include:",
    "dataset_tool_repo": "The paper does not explicitly mention a link to a dataset or tool repository. Therefore, it is unclear if a public repository is provided.",
    "publicly_available": "No",
    "llm_prompt_strategy": "Yes, the paper employs a prompt engineering strategy that includes:"
  },
  {
    "file_name": "Software Vulnerability and Functionality Assessment using Large Language Models.pdf",
    "bug_type": "The bug types investigated in the paper include security vulnerabilities and functionality issues. The vulnerabilities are derived from the SecurityEval dataset, which contains real-world vulnerabilities as per the CWE system. Therefore, they are considered real-world bugs.",
    "bug_origin": "Real-world",
    "programming_language": "The programming language used in the experiments is Python.",
    "benchmarks_or_datasets": "The paper utilizes three datasets:",
    "dataset_tool_repo": "The context does not provide a specific link to a dataset/tool repository.",
    "publicly_available": "No",
    "llm_prompt_strategy": "Yes, the paper employs several prompt strategies, including:"
  },
  {
    "file_name": "Large Language Model for Vulnerability Detection_ Emerging Results and Future Directions.pdf",
    "bug_type": "The bug types discussed in the paper are related to software vulnerabilities, specifically those identified through vulnerability-fixing commits. The vulnerabilities are derived from real-world software repositories, making them real-world vulnerabilities.",
    "bug_origin": "Real-world",
    "programming_language": "The programming languages focused on in this study are C and C++.",
    "benchmarks_or_datasets": "The paper uses a vulnerability-fixing commit dataset collected by Pan et al. This dataset includes software versions prior to vulnerability-fixing commits and labels functions with lines changed in a patch as vulnerable.",
    "dataset_tool_repo": "Yes, the paper mentions that a replication package is made publicly available for future studies, but it does not provide a specific link in the provided context.",
    "publicly_available": "No",
    "llm_prompt_strategy": "Yes, the paper discusses various prompt strategies used to enhance the performance of LLMs in vulnerability detection. These include:"
  },
  {
    "file_name": "Fuzz4All_ Universal Fuzzing with Large Language Models.pdf",
    "bug_type": "The bugs detected by Fuzz4All are real-world bugs. The paper mentions that Fuzz4All detected 98 bugs, with 64 of them confirmed by developers as previously unknown.",
    "bug_origin": "Real-world",
    "programming_language": "Fuzz4All is evaluated on six programming languages: C, C++, SMT, Go, Java, and Python.",
    "benchmarks_or_datasets": "The benchmarks include nine systems under test (SUTs): GCC, Clang, Z3, CVC5, Go standard library, OpenJDK (javac), and Qiskit. The paper also mentions using standard documentation for these languages as user input for fuzzing.",
    "dataset_tool_repo": "The paper does not explicitly mention a dataset or tool repository link. However, it states that a detailed list of reported bugs and issue links can be found in their artifact, which suggests that additional resources may be available.",
    "publicly_available": "No",
    "llm_prompt_strategy": ""
  },
  {
    "file_name": "Lost in Translation_ A Study of Bugs Introduced by Large Language Models while Translating Code.pdf",
    "bug_type": "The bug types identified in the study are categorized into 15 categories organized into five groups. These bugs are primarily real-world bugs, as the study investigates translation bugs in both crafted benchmarks and real-world projects.",
    "bug_origin": "Real-world",
    "programming_language": "The programming languages used in the study are C, C++, Go, Java, and Python.",
    "benchmarks_or_datasets": "The datasets used in the study include:",
    "dataset_tool_repo": "Yes, a dataset/tool repository is provided. The link to the repository is [7] (the actual URL is not specified in the provided text).",
    "publicly_available": "Yes",
    "llm_prompt_strategy": ""
  },
  {
    "file_name": "Large Language Models for Test-Free Fault Localization.pdf",
    "bug_type": "The bug types discussed in the paper include general logic defects and security vulnerabilities. The bugs are real-world, as they are sourced from established datasets like Defects4J, BugsInPy, and Devign.",
    "bug_origin": "Real-world",
    "programming_language": "The programming languages used in the study are Java, Python, and C.",
    "benchmarks_or_datasets": "The datasets used include:",
    "dataset_tool_repo": "Yes, a dataset/tool repository is provided. The link is: [https://github.com/squaresLab/LLMAO](https://github.com/squaresLab/LLMAO).",
    "publicly_available": "Yes",
    "llm_prompt_strategy": ""
  },
  {
    "file_name": "A Light Bug Triage Framework for Applying Large Pre-trained Language Model.pdf",
    "bug_type": "The bugs are from real-world datasets, specifically from projects like Google Chromium, Mozilla Core, and Mozilla Firefox.",
    "bug_origin": "Real-world",
    "programming_language": "The paper does not specify a particular programming language used for the bug reports. It focuses on the bug triage framework rather than the programming language.",
    "benchmarks_or_datasets": "The benchmarks/datasets used are:",
    "dataset_tool_repo": "The provided context does not mention a specific link to a dataset or tool repository.",
    "publicly_available": "No",
    "llm_prompt_strategy": "The paper discusses using a large pre-trained language model (RoBERTa) as a text embedding module for capturing semantic information from bug reports. It also mentions a knowledge preservation fine-tuning strategy and a combined thinking architecture to handle overthinking problems, but it does not detail a specific prompt strategy for LLMs."
  },
  {
    "file_name": "Exploring ChatGPT for Toxicity Detection in GitHub.pdf",
    "bug_type": "The bug type refers to toxicity in comments on GitHub. The dataset used is real-world, as it consists of actual GitHub issue comments that were manually curated.",
    "bug_origin": "Real-world",
    "programming_language": "The paper does not specify a programming language, as it focuses on the application of ChatGPT for toxicity detection rather than implementation in a specific programming language.",
    "benchmarks_or_datasets": "The benchmark dataset used is a manually curated dataset of 1597 GitHub issue comments, which includes 102 toxic and 1495 non-toxic comments.",
    "dataset_tool_repo": "Yes, a dataset/tool repository is provided. The link is: [https://anonymous.4open.science/r/opensource-toxicity-0236/README.md](https://anonymous.4open.science/r/opensource-toxicity-0236/README.md).",
    "publicly_available": "Yes",
    "llm_prompt_strategy": ""
  }
]