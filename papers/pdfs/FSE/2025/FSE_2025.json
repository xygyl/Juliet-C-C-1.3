[
  {
    "file_name": "BitsAI-CR_ Automated Code Review via LLM in Practice.pdf",
    "bug_type": "The bug types addressed include code defects, security vulnerabilities, and performance issues. The bugs are primarily real-world, as the system is designed to analyze actual code changes in a production environment at ByteDance.",
    "bug_origin": "Real-world",
    "programming_language": "The programming languages mentioned include Go, JavaScript, TypeScript, Python, and Java.",
    "benchmarks_or_datasets": "The paper mentions a dataset consisting of 120,000 code review comments extracted from ByteDance's internal code repository, which includes both static analysis results and manual review feedback. Additionally, 1,397 cases were sampled from the production codebase for offline evaluation.",
    "dataset_tool_repo": "The paper does not provide a specific link to a dataset or tool repository.",
    "publicly_available": "No",
    "llm_prompt_strategy": "Yes, the paper describes a systematic approach for context preparation that includes partitioning code diffs, expanding segmented code blocks, and implementing a detailed change annotation system. Additionally, it mentions using a \"Conclusion-First\" reasoning pattern for the ReviewFilter component to enhance comment validation."
  },
  {
    "file_name": "Demystifying Verbatim Memorization in Large Language Models.pdf",
    "bug_type": "The bug type discussed in the paper is related to **verbatim memorization** in large language models (LLMs). This issue is primarily observed in **real-world** scenarios, as it pertains to the models' outputs that can match training examples verbatim, which raises concerns regarding copyright and privacy.",
    "bug_origin": "Real-world",
    "programming_language": "The paper does not explicitly mention a programming language, but it refers to using **PyTorch** for model training and experimentation, which is typically associated with Python.",
    "benchmarks_or_datasets": "The paper utilizes the **Pythia family of models** and the **Pile dataset** (specifically the deduped version) for training and evaluation. It also mentions using a curated set of sequences sampled from internet content published after the Pile cutoff date.",
    "dataset_tool_repo": "The paper does not provide a direct link to a dataset/tool repository in the provided context. However, it mentions using tools like **Data portraits** and **infini-gram** for verifying overlaps with the Pile dataset.",
    "publicly_available": "No",
    "llm_prompt_strategy": "The paper discusses using **interchange interventions** and **prompting with substrings** of various lengths to measure verbatim memorization length. It also mentions using **Position Perturbations** and **Semantic Perturbations** as strategies for stress testing unlearning methods."
  },
  {
    "file_name": "Large Language Models for In-File Vulnerability Localization can be \u201cLost in the End\u201d.pdf",
    "bug_type": "The bug types studied are CWE-22 (Path Traversal), CWE-79 (XSS), and CWE-89 (SQL Injection). These are real-world vulnerabilities collected from the CVE catalog.",
    "bug_origin": "Real-world",
    "programming_language": "The programming languages used include PHP, TypeScript, JavaScript, HTML, Java, Go, Python, Ruby, and C.",
    "benchmarks_or_datasets": "The dataset used is extracted from the CVE catalog, specifically focusing on vulnerabilities that affect single files. The study includes 794 vulnerable files and their corresponding patched versions.",
    "dataset_tool_repo": "The text does not provide a specific link to a dataset or tool repository.",
    "publicly_available": "No",
    "llm_prompt_strategy": "Yes, the prompt strategy used is called in-context learning. The prompt provided to the LLMs includes an example of the expected output structure, asking the model to analyze the file content and identify any lines that may contain a bug of a specified CWE type. The prompt is structured to elicit a very short explanation, the bugged line, and a yes/no answer indicating whether a bug was found."
  },
  {
    "file_name": "Doc2OracLL_ Investigating the Impact of Documentation on LLM-based Test Oracle Generation.pdf",
    "bug_type": "The bugs studied in the paper are real-world bugs, specifically sourced from the Defects4J dataset, which contains bugs from real-world Java projects.",
    "bug_origin": "Real-world",
    "programming_language": "The programming language used in the study is Java.",
    "benchmarks_or_datasets": "The benchmarks/datasets used include:",
    "dataset_tool_repo": "Yes, the paper mentions that the dataset and tools are available, but the specific link is not provided in the context. You may need to refer to the original paper for the exact repository link.",
    "publicly_available": "No",
    "llm_prompt_strategy": ""
  },
  {
    "file_name": "Cross-lingual Code Clone Detection:\nWhen LLMs Fail Short Against Embedding-based Classifier.pdf",
    "bug_type": "The bug type refers to code clones, which can be considered real-world issues in software development. The paper discusses the detection of cross-lingual code clones, which are prevalent in collaborative software development.",
    "bug_origin": "Real-world",
    "programming_language": "The study evaluates the performance of models across **eleven programming languages**, but specific languages are not listed in the provided context. However, it mentions Java and C# as examples of languages with syntactical similarity.",
    "benchmarks_or_datasets": "The paper uses two widely accepted datasets: **XLCoST** and **CodeNet**.",
    "dataset_tool_repo": "The provided context does not mention a specific link to a dataset or tool repository.",
    "publicly_available": "No",
    "llm_prompt_strategy": ""
  },
  {
    "file_name": "PATCH_ Empowering Large Language Model with Programmer-Intent Guidance and Collaborative-Behavior Simulation for Automatic Bug Fixing.pdf",
    "bug_type": "The bug type is real-world bugs, as the paper utilizes the BFP benchmark, which includes a diverse range of real-world bugs.",
    "bug_origin": "Real-world",
    "programming_language": "The programming language used is Java.",
    "benchmarks_or_datasets": "The primary benchmark used is the BFP benchmark, which consists of paired bug-fixing instances extracted from real-world GitHub repositories.",
    "dataset_tool_repo": "Yes, the tool/benchmark is publicly available. The paper mentions that the replicate package of PATCH is released on Zenodo, but the specific link is not provided in the text you shared.",
    "publicly_available": "Yes",
    "llm_prompt_strategy": ""
  },
  {
    "file_name": "Automated Soap Opera Testing Directed by LLMs and Scenario Knowledge_ Feasibility, Challenges, and Road Ahead.pdf",
    "bug_type": "The bugs identified in the study are real-world bugs, as they were discovered during the testing of actual applications (Firefox, WordPress, and AntennaPod) and reported to their respective development teams.",
    "bug_origin": "Real-world",
    "programming_language": "The paper does not explicitly mention a specific programming language used in the testing or development of the automated soap opera testing system. However, the applications under test (Firefox, WordPress, AntennaPod) are primarily developed using languages such as Java (for Android apps) and JavaScript (for web applications).",
    "benchmarks_or_datasets": "The study uses three open-source Android apps (Firefox, WordPress, and AntennaPod) as the software under test (SUT). Each app has a dataset of 10 soap opera tests covering diverse features. The knowledge graph (SKG) for Firefox is built from 7,947 Bugzilla bug reports, for WordPress from 21,010 GitHub issues and pull requests, and for AntennaPod from 7,317 GitHub issues and pull requests.",
    "dataset_tool_repo": "The paper does not provide a direct link to a dataset or tool repository.",
    "publicly_available": "No",
    "llm_prompt_strategy": "Yes, the paper describes a role-play prompt strategy used to specialize the LLMs for specific tasks. The prompts include components such as Role Assignment, Task Description, and Output Guidelines, which help the LLMs understand their roles in generating actionable plans, executing UI instructions, and identifying bugs."
  },
  {
    "file_name": "Hallucination Detection in Large Language Models with Metamorphic Relations.pdf",
    "bug_type": "The bug type is \"hallucinations\" in Large Language Models (LLMs), specifically fact-conflicting hallucinations. These hallucinations can be considered real-world issues as they involve generating coherent but factually incorrect or irrelevant outputs.",
    "bug_origin": "Real-world",
    "programming_language": "The paper does not specify a particular programming language used for the implementation of the methods discussed.",
    "benchmarks_or_datasets": "The benchmarks or datasets used are:",
    "dataset_tool_repo": "Yes, the paper mentions an improved version of the TruthfulQA dataset called \"TruthfulQA-Enhanced,\" but it does not provide a specific link to a dataset/tool repository in the provided text.",
    "publicly_available": "No",
    "llm_prompt_strategy": ""
  },
  {
    "file_name": "LogLLM_ Log-based Anomaly Detection Using.pdf",
    "bug_type": "The bug type refers to anomalies in system logs, and they are real-world anomalies as the datasets used for evaluation contain real log messages from operational systems.",
    "bug_origin": "Real-world",
    "programming_language": "The tool is coded in Python.",
    "benchmarks_or_datasets": "The benchmarks or datasets used are:",
    "dataset_tool_repo": "Yes, the source code for LogLLM is available at the following link: [LogLLM GitHub Repository](https://github.com/guanwei49/LogLLM).",
    "publicly_available": "Yes",
    "llm_prompt_strategy": ""
  },
  {
    "file_name": "Securing Large Language Models_ Threats, Vulnerabilities and Responsible Practices.pdf",
    "bug_type": "The bug types discussed in the paper include vulnerabilities related to information leakage, adversarial attacks, data poisoning, and backdoor attacks. These vulnerabilities can be categorized as real-world threats, as they have practical implications for the deployment and use of LLMs in various applications.",
    "bug_origin": "Real-world",
    "programming_language": "The paper does not specify a particular programming language used for the implementation of the discussed models or experiments. However, it references various models and techniques that are typically implemented in languages such as Python, which is commonly used in machine learning and natural language processing.",
    "benchmarks_or_datasets": "The paper mentions several datasets and benchmarks indirectly through references to studies and experiments, but it does not provide a specific list of datasets used in its own research. It discusses various studies that utilize datasets for evaluating LLMs, including those for assessing memorization and data leakage.",
    "dataset_tool_repo": "The paper does not provide a specific dataset or tool repository link. It discusses various methods and frameworks but does not include direct links to repositories.",
    "publicly_available": "No",
    "llm_prompt_strategy": "The paper discusses various prompt manipulation strategies, including prompt injection and prompt leaking, as well as techniques for crafting prompts to elicit specific responses from LLMs. It also mentions the use of adversarial prompts to test the vulnerabilities of LLMs."
  },
  {
    "file_name": "Code Change Intention, Development Artifact and History Vulnerability_ Putting Them Together for Vulnerability Fix Detection by LLM.pdf",
    "bug_type": "The bug type discussed in the paper pertains to vulnerabilities in software, specifically vulnerability fix commits. The dataset used includes real-world vulnerability fix commits collected from the National Vulnerability Database (NVD).",
    "bug_origin": "Real-world",
    "programming_language": "The paper mentions that the dataset consists of vulnerability fix commits from 7 major programming languages: Java, C, C++, Rust, JavaScript, Python, and Go.",
    "benchmarks_or_datasets": "The paper introduces a newly created dataset called the **BigVulFix dataset**, which consists of 1,689 vulnerability fix commits collected after 2023.",
    "dataset_tool_repo": "Yes, the datasets and code used in the study are openly available in their replication package. However, the specific link to the repository is not provided in the excerpt.",
    "publicly_available": "Yes",
    "llm_prompt_strategy": ""
  }
]