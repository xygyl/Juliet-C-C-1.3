[
  {
    "file_name": "RUSTASSISTANT_ Using LLMs to Fix Compilation errors in rust.pdf",
    "bug_type": "The bug types are real-world compilation errors collected from various sources, including Stack Overflow questions and GitHub commits.",
    "bug_origin": "Real-world",
    "programming_language": "The programming language used is Rust.",
    "benchmarks_or_datasets": "The benchmarks/datasets used include:",
    "dataset_tool_repo": "Yes, the authors plan to open-source both their dataset and the implementation of RUSTASSISTANT. However, the specific link is not provided in the context.",
    "publicly_available": "Yes",
    "llm_prompt_strategy": ""
  },
  {
    "file_name": "LLM4PLC_ Harnessing Large Language Models for Verifiable Programming of PLCs in Industrial Control Systems.pdf",
    "bug_type": "The paper discusses bugs related to syntax errors in PLC code generated by LLMs. These bugs are primarily synthetic, as they arise from the automated code generation process rather than from real-world applications.",
    "bug_origin": "Real-world",
    "programming_language": "The programming language used is Structured Text (ST), which is part of the IEC 61131-3 standard for PLC programming.",
    "benchmarks_or_datasets": "The paper mentions the OSCAT IEC 61131-3 Library as the source for generating the datasets. Three datasets are derived from this library: (1) Generation, (2) Completion, and (3) Fixing.",
    "dataset_tool_repo": "The context does not provide a specific link to a dataset/tool repository. It mentions that the datasets were created from the OSCAT IEC 61131-3 Library but does not indicate a publicly accessible repository.",
    "publicly_available": "No",
    "llm_prompt_strategy": ""
  },
  {
    "file_name": "Model Editing for LLMs4Code_ How Far are We_.pdf",
    "bug_type": "The bug types discussed in the paper are related to inaccuracies in code knowledge embedded in LLMs4Code, which can lead to bugs or vulnerabilities in production environments. The study focuses on real-world scenarios where updates to code knowledge within a model are necessary.",
    "bug_origin": "Real-world",
    "programming_language": "The programming language used in the datasets is Python.",
    "benchmarks_or_datasets": "The benchmarks/datasets used are:",
    "dataset_tool_repo": "Yes, a dataset/tool repository is provided. The link is: [https://github.com/xpq-tech/code-llmedit.git](https://github.com/xpq-tech/code-llmedit.git).",
    "publicly_available": "Yes",
    "llm_prompt_strategy": ""
  },
  {
    "file_name": "LLM Assistance for Memory Safety.pdf",
    "bug_type": "The bug type is memory safety violations. The examples provided in the paper are derived from real-world C programs used in their evaluation.",
    "bug_origin": "Real-world",
    "programming_language": "The programming language used is C.",
    "benchmarks_or_datasets": "The benchmarks used include a subset of the Olden and Ptrdist benchmarks, as well as real-world codebases such as vsftpd, icecast, and libarchive.",
    "dataset_tool_repo": "The paper does not explicitly mention a dataset/tool repository link.",
    "publicly_available": "No",
    "llm_prompt_strategy": ""
  },
  {
    "file_name": "Instruct or Interact_ Exploring and Eliciting LLMs\u2019 Capability in Code Snippet Adaptation Through Prompt Engineering.pdf",
    "bug_type": "The bug types identified in the study are primarily related to adaptation failures, including context-related errors, overlooked defects, and misalignments. The study does not explicitly categorize these as synthetic or real-world, but it focuses on real-world adaptation scenarios using the ClassEval benchmark, which simulates real software development contexts.",
    "bug_origin": "Real-world",
    "programming_language": "The programming language used in the study is Python.",
    "benchmarks_or_datasets": "The benchmark used is the ClassEval benchmark, which comprises 100 Python classes and their associated test suites.",
    "dataset_tool_repo": "Yes, the paper mentions that accessible source code and annotated data will facilitate the replication and application of the study. However, the specific link to the dataset/tool repository is not provided in the context.",
    "publicly_available": "No",
    "llm_prompt_strategy": "The paper discusses several prompt strategies, including:"
  },
  {
    "file_name": "TOGLL_ Correct and Strong Test Oracle Generation with LLMs.pdf",
    "bug_type": "The paper discusses both synthetic and real-world bugs. The evaluation includes a comprehensive study on 25 real-world large-scale Java projects and also references the Defects4J dataset, which contains real bugs.",
    "bug_origin": "Real-world",
    "programming_language": "The programming language used in the study is Java.",
    "benchmarks_or_datasets": "The paper utilizes the SF110 dataset, which consists of 110 open-source Java projects, and the OracleEval25 dataset, which comprises 25 large-scale industrial standard Java projects. Additionally, it references the Defects4J dataset for real bug detection.",
    "dataset_tool_repo": "The context does not provide a specific link to a dataset/tool repository. However, it mentions that the datasets are constructed from publicly available sources like SourceForge and GitHub.",
    "publicly_available": "No",
    "llm_prompt_strategy": ""
  },
  {
    "file_name": "LLM-Agents Driven Automated Simulation Testing and Analysis of small Uncrewed Aerial Systems.pdf",
    "bug_type": "The bug types discussed in the paper are primarily related to real-world incidents involving small Uncrewed Aerial Systems (sUAS). The scenarios generated for testing are informed by actual past incidents, indicating a focus on real-world bugs.",
    "bug_origin": "Real-world",
    "programming_language": "The paper mentions the use of Python for parsing data structures and generating scripts, particularly in the context of building the knowledge base for the Analytics-Agent.",
    "benchmarks_or_datasets": "The paper describes the creation of a dataset of 7 PX4 flight logs with artificially injected sensor failures. These logs include common real-world sensor failures such as GPS loss, accelerometer issues, and others.",
    "dataset_tool_repo": "Yes, the codebase and supplementary materials for the framework are available at the following link: [https://github.com/UAVLab-SLU/AutoSimTestFramework](https://github.com/UAVLab-SLU/AutoSimTestFramework).",
    "publicly_available": "Yes",
    "llm_prompt_strategy": "The paper discusses several prompt strategies used in the framework, including:"
  },
  {
    "file_name": "Fixing Rust Compilation Errors using LLMs.pdf",
    "bug_type": "The bug types are compilation errors in Rust. They are a mix of synthetic (from microbenchmarks) and real-world (from Stack Overflow and GitHub commits).",
    "bug_origin": "Real-world",
    "programming_language": "The programming language used is Rust.",
    "benchmarks_or_datasets": "The benchmarks/datasets used include:",
    "dataset_tool_repo": "Yes, the authors plan to open-source both their dataset and the implementation of RustAssistant, but a specific link is not provided in the text.",
    "publicly_available": "No",
    "llm_prompt_strategy": "Yes, the paper describes a specific prompt construction strategy that includes:"
  },
  {
    "file_name": "IRIS_ LLM-Assisted Static Analysis for Detecting Security Vulnerabilities.pdf",
    "bug_type": "The bug type discussed in the paper includes code injection vulnerabilities (CWE-094). The vulnerabilities are real-world, as they are detected in actual Java libraries and projects.",
    "bug_origin": "Real-world",
    "programming_language": "The programming language used in the study is Java.",
    "benchmarks_or_datasets": "The paper introduces a curated dataset called CWE-Bench-Java, which contains 120 security vulnerabilities across four classes in real-world Java projects.",
    "dataset_tool_repo": "Yes, the dataset/tool repository is provided. The link is not explicitly mentioned in the provided context, so it cannot be included.",
    "publicly_available": "No",
    "llm_prompt_strategy": ""
  },
  {
    "file_name": "LLMSecConfig_ An LLM-Based Approach for Fixing Software Container Misconfigurations.pdf",
    "bug_type": "The bug type refers to security misconfigurations in container orchestration environments, specifically Kubernetes configurations. These are real-world misconfigurations as they are derived from actual usage patterns in widely used projects.",
    "bug_origin": "Real-world",
    "programming_language": "The primary programming language used is Python, particularly for the implementation of the static analysis tool (Checkov) integrated into the framework.",
    "benchmarks_or_datasets": "The evaluation is conducted using a custom dataset of 1,000 real-world Kubernetes configurations collected from ArtifactHub. This dataset includes configurations that exhibit various security misconfigurations identified through static analysis.",
    "dataset_tool_repo": "Yes, a dataset/tool repository is provided. The complete implementation, including the collected dataset of Kubernetes misconfigurations, source code of the framework, and evaluation scripts, can be found at [https://figshare.com/s/2a9be8ccfbec9d8ba199](https://figshare.com/s/2a9be8ccfbec9d8ba199).",
    "publicly_available": "Yes",
    "llm_prompt_strategy": ""
  },
  {
    "file_name": "Unseen Horizons_ Unveiling the Real Capability of LLM Code Generation Beyond the Familiar.pdf",
    "bug_type": "The bug types discussed in the paper are primarily real-world bugs, as they are derived from real-world production projects and involve actual code modifications and dependencies.",
    "bug_origin": "Real-world",
    "programming_language": "The programming language used in the study is C.",
    "benchmarks_or_datasets": "The paper introduces a new benchmark called OBFUSEVAL, which is built from real-world projects on GitHub. It also references existing benchmarks like HumanEval and SWE-BENCH, but emphasizes the limitations of these benchmarks in evaluating LLMs' capabilities.",
    "dataset_tool_repo": "The context does not provide a specific link to a dataset/tool repository. It mentions the construction of the OBFUSEVAL benchmark but does not specify if it is publicly available or provide a link.",
    "publicly_available": "No",
    "llm_prompt_strategy": "Yes, the paper describes a prompt strategy that includes:"
  },
  {
    "file_name": "An LLM-Based Agent-Oriented Approach for Automated Code Design Issue Localization.pdf",
    "bug_type": "The bug types discussed in the paper are design issues related to software design, such as poor modularity, tight coupling, and excessive complexity. These are real-world issues as they pertain to actual codebases.",
    "bug_origin": "Real-world",
    "programming_language": "The programming languages mentioned in the paper are Java and Python.",
    "benchmarks_or_datasets": "The paper uses a refactoring dataset released by Aniche et al. [13], which contains 11K diverse projects from Fdroid, Apache, and GitHub repositories.",
    "dataset_tool_repo": "Yes, a replication package, including the source code and dataset, is available at [36].",
    "publicly_available": "Yes",
    "llm_prompt_strategy": ""
  },
  {
    "file_name": "RepairAgent_ An Autonomous, LLM-Based.pdf",
    "bug_type": "The bugs are real-world bugs, specifically from the Defects4J dataset, which contains real bugs from Java projects.",
    "bug_origin": "Real-world",
    "programming_language": "The programming language used is Java.",
    "benchmarks_or_datasets": "The benchmarks used are from the Defects4J dataset, which consists of 835 real-world bugs from 17 Java projects.",
    "dataset_tool_repo": "The context does not provide a specific link to a dataset/tool repository.",
    "publicly_available": "No",
    "llm_prompt_strategy": ""
  },
  {
    "file_name": "LiCoEval_ Evaluating LLMs on License Compliance in Code Generation.pdf",
    "bug_type": "The bug type pertains to license compliance issues in code generation by LLMs. These issues are considered real-world as they relate to the legal implications of using generated code that may infringe on open-source licenses.",
    "bug_origin": "Real-world",
    "programming_language": "The programming language used in the evaluation is Python.",
    "benchmarks_or_datasets": "The benchmarks or datasets used include:",
    "dataset_tool_repo": "Yes, the dataset/tool repository is provided. The benchmark LICOEVAL can be accessed at the link mentioned in the paper (though the specific link is not provided in your context, it is indicated as [92]).",
    "publicly_available": "Yes",
    "llm_prompt_strategy": ""
  },
  {
    "file_name": "Are LLMs Correctly Integrated into Software Systems_.pdf",
    "bug_type": "The bug types identified in the study are real-world integration defects in LLM-enabled software.",
    "bug_origin": "Real-world",
    "programming_language": "The programming languages used in the benchmark include Python (74%), TypeScript (17%), and others (9%).",
    "benchmarks_or_datasets": "The study does not specify traditional benchmarks but mentions a collection of 100 open-source LLM-enabled software projects from GitHub and over 3,000 issue reports analyzed for defects.",
    "dataset_tool_repo": "Yes, a defect library named HYDRANGEA containing all identified defects is provided. The repository can be found at GitHub, but the specific link is not included in the context provided.",
    "publicly_available": "Yes",
    "llm_prompt_strategy": ""
  },
  {
    "file_name": "Insights and Current Gaps in Open-Source LLM Vulnerability Scanners_ A Comparative Analysis.pdf",
    "bug_type": "The bug types discussed in the paper include vulnerabilities related to LLMs, such as jailbreak attacks, prompt injections, and insecure code generation. These vulnerabilities can be considered real-world as they pertain to actual security risks associated with the deployment of LLMs in various applications.",
    "bug_origin": "Real-world",
    "programming_language": "The paper does not explicitly mention a specific programming language used for the scanners. However, it references tools and frameworks commonly associated with Python, which is widely used in AI and machine learning contexts.",
    "benchmarks_or_datasets": "The paper mentions a labeled dataset consisting of 1,000 samples as a foundational starting point for quantifying the scanners' reliability. It also discusses the use of adversarial prompts generated for testing the scanners against various LLMs.",
    "dataset_tool_repo": "Yes, a labeled dataset is provided. The link to the dataset is: [Labelled adversarial prompts dataset](https://github.com/deadbits/vigil-llm).",
    "publicly_available": "No",
    "llm_prompt_strategy": ""
  },
  {
    "file_name": "Cracks in The Stack_ Hidden Vulnerabilities and Licensing Risks in LLM Pre-Training Datasets.pdf",
    "bug_type": "The bugs discussed in the paper are real-world vulnerabilities and bugs found in the training datasets used for Large Language Models (LLMs).",
    "bug_origin": "Real-world",
    "programming_language": "The paper mentions that the Stack v2 dataset includes code in over 600 programming and markup languages.",
    "benchmarks_or_datasets": "The primary dataset used for evaluation is the Stack v2 dataset, which contains over 3 billion files in various programming languages.",
    "dataset_tool_repo": "Yes, a replication package is available at the following link: [https://zenodo.org/records/14175945](https://zenodo.org/records/14175945).",
    "publicly_available": "Yes",
    "llm_prompt_strategy": ""
  },
  {
    "file_name": "LLM-Assisted Static Analysis for Detecting Security Vulnerabilities.pdf",
    "bug_type": "The bug type discussed in the paper is a **Code Injection vulnerability (CWE-094)**. The vulnerabilities are from **real-world** projects, specifically curated in the CWE-Bench-Java dataset.",
    "bug_origin": "Real-world",
    "programming_language": "The programming language used is **Java**.",
    "benchmarks_or_datasets": "The benchmark used is the **CWE-Bench-Java**, which is a curated dataset of vulnerabilities in Java libraries.",
    "dataset_tool_repo": "Yes, the dataset is provided, but the specific link is not included in the provided context. You may need to refer to the original paper for the exact link.",
    "publicly_available": "Yes",
    "llm_prompt_strategy": ""
  },
  {
    "file_name": "CKGFuzzer_ LLM-Based Fuzz Driver Generation Enhanced By Code Knowledge Graph.pdf",
    "bug_type": "The bugs identified by CKGFuzzer include real-world bugs, as the paper mentions that 11 real bugs were detected, including nine previously unreported bugs.",
    "bug_origin": "Real-world",
    "programming_language": "The programming language used in the evaluation of CKGFuzzer is C, as it primarily focuses on C-based libraries.",
    "benchmarks_or_datasets": "CKGFuzzer was evaluated using eight open-source libraries: c-ares, cjson, curl, lcms, libpcap, libtiff, libvpx, and zlib.",
    "dataset_tool_repo": "Yes, a dataset/tool repository is provided. The link is: [https://github.com/security-pride/CKGFuzzer](https://github.com/security-pride/CKGFuzzer).",
    "publicly_available": "Yes",
    "llm_prompt_strategy": ""
  },
  {
    "file_name": "Can GPT-O1 Kill All Bugs_ An Evaluation of GPT-Family LLMs on QuixBugs.pdf",
    "bug_type": "The bugs are synthetic, as they are taken from the QuixBugs benchmark, which consists of predefined buggy programs designed for evaluation purposes.",
    "bug_origin": "Synthetic",
    "programming_language": "The programming language used is Python.",
    "benchmarks_or_datasets": "The benchmark used is QuixBugs (Lin et al., 2017).",
    "dataset_tool_repo": "The provided context does not mention a specific dataset/tool repository link.",
    "publicly_available": "No",
    "llm_prompt_strategy": ""
  },
  {
    "file_name": "Are Large Language Models Memorizing Bug Benchmarks_.pdf",
    "bug_type": "The bug types discussed in the paper are real-world bugs from open-source software projects.",
    "bug_origin": "Real-world",
    "programming_language": "The programming languages used in the benchmarks include Java and Python.",
    "benchmarks_or_datasets": "The benchmarks or datasets mentioned include:",
    "dataset_tool_repo": "The context does not provide a specific link to a dataset/tool repository. Therefore, it is unclear if a repository is provided.",
    "publicly_available": "No",
    "llm_prompt_strategy": "The paper mentions using strategies from prior work to evaluate models for potential data leakage, including membership checks, Negative Log Likelihood (NLL), and n-gram accuracy. The prompts are designed to assess how well the models can reproduce code snippets based on the context provided."
  },
  {
    "file_name": "LSAST_ Enhancing Cybersecurity through LLM-supported Static Application Security Testing .pdf",
    "bug_type": "The bug types discussed in the paper include various vulnerabilities such as OS command injection and type confusion. The vulnerabilities are primarily real-world, as the paper mentions testing on actual applications like DVWA, DVNA, OWASP Juice Shop, and WebGoat, which are designed with known vulnerabilities.",
    "bug_origin": "Real-world",
    "programming_language": "The programming languages used in the experiments include PHP, JavaScript, TypeScript, and Java, as indicated by the applications tested.",
    "benchmarks_or_datasets": "The benchmarks used include open-source security testing projects such as DVWA (Damn Vulnerable Web Application), DVNA (Damn Vulnerable NodeJS Application), OWASP Juice Shop, and WebGoat. Additionally, a dataset of 873 vulnerability reports was gathered using the Hacktivity API.",
    "dataset_tool_repo": "The context does not provide a specific link to a dataset or tool repository. Therefore, it appears that no direct link is mentioned in the provided text.",
    "publicly_available": "No",
    "llm_prompt_strategy": ""
  }
]
