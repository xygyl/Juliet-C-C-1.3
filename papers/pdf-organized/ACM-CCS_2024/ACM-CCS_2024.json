[
  {
    "file_name": "ReSym_ Harnessing LLMs to Recover Variable and Data Structure.pdf",
    "bug_type": "The bug type pertains to the recovery of variable names, types, and user-defined data structures from decompiled code, which is a real-world issue in binary analysis and reverse engineering.",
    "bug_origin": "Real-world",
    "programming_language": "The programming languages used are C and C++.",
    "benchmarks_or_datasets": "The paper mentions a dataset created by compiling 7,416 popular C and C++ projects into 113,696 binary files from GitHub, specifically focusing on executable binary programs created between 2012 and 2022 with more than 20 stars.",
    "dataset_tool_repo": "Yes, the paper indicates that a complete list of common synonyms and additional resources can be found in their artifacts, but it does not provide a direct link in the provided context.",
    "publicly_available": "No",
    "llm_prompt_strategy": ""
  },
  {
    "file_name": "To Err is Machine_ Vulnerability Detection Challenges LLM Reasoning.pdf",
    "bug_type": "The bug type discussed in the paper is **Buffer Overflow (BOF)**. The dataset used for analysis consists of **real-world** vulnerabilities.",
    "bug_origin": "Real-world",
    "programming_language": "The programming languages used in the study are **C/C++**.",
    "benchmarks_or_datasets": "The benchmark or dataset used is **SVEN (He & Vechev, 2023)**, which contains 772 vulnerable and fixed functions from real-world C/C++ projects.",
    "dataset_tool_repo": "Yes, a dataset/tool repository is provided. The link is: [https://doi.org/10.6084/m9.figshare.27368025](https://doi.org/10.6084/m9.figshare.27368025).",
    "publicly_available": "Yes",
    "llm_prompt_strategy": "The paper mentions the use of **baseline prompting methods**, including **Basic (zero-shot)** prompting, and also discusses a specific strategy called **Chain-of-Thought with Annotations (CoT-Annotations)** to improve understanding of vulnerabilities."
  },
  {
    "file_name": "zkLLM_ Zero Knowledge Proofs for Large Language Models.pdf",
    "bug_type": "The paper does not explicitly categorize bugs as synthetic or real-world. However, it discusses the challenges associated with verifying the legitimacy of outputs from large language models (LLMs) in real-world scenarios, particularly in legal contexts. Therefore, the focus appears to be on real-world concerns regarding the authenticity and legality of LLM outputs.",
    "bug_origin": "Real-world",
    "programming_language": "The implementation of zkLLM is based on CUDA, which is a parallel computing platform and application programming interface (API) model created by NVIDIA. CUDA is typically used with C/C++.",
    "benchmarks_or_datasets": "The paper mentions using samples from the C4 dataset for verifiable inferences. Additionally, it evaluates zkLLM on two classes of open-source LLMs, namely OPT and LLaMa-2.",
    "dataset_tool_repo": "The provided context does not mention a specific dataset or tool repository link. Therefore, it appears that no direct link is provided in the text.",
    "publicly_available": "No",
    "llm_prompt_strategy": "The paper discusses the auditing process where law enforcement queries the model using designated prompts to test if the LLM generates illegal output. However, it does not specify a detailed prompt strategy beyond this context."
  },
  {
    "file_name": "Vul-RAG_ Enhancing LLM-based Vulnerability Detection via Knowledge-level RAG.pdf",
    "bug_type": "The bug types discussed in the paper are related to security vulnerabilities in software, specifically those identified by Common Vulnerabilities and Exposures (CVE). The vulnerabilities are real-world, as they are derived from actual CVEs.",
    "bug_origin": "Real-world",
    "programming_language": "The programming language used in the context of the paper is C/C++, as indicated by the mention of Linux kernel CVEs and the focus on function-level vulnerability detection.",
    "benchmarks_or_datasets": "The paper constructs a new benchmark called PairVul, which contains 4,314 pairs of vulnerable and patched code functions across 2,073 CVEs. It also references existing benchmarks such as BigVul, Devign, and Reveal for comparison.",
    "dataset_tool_repo": "The context does not provide a specific link to a dataset or tool repository. Therefore, it is unclear if a repository is available.",
    "publicly_available": "No",
    "llm_prompt_strategy": "Yes, the paper mentions the use of prompt engineering strategies, including Chain-of-Thought (CoT) and few-shot learning, to facilitate more accurate vulnerability detection. Specific prompts are also detailed for extracting functional semantics, vulnerability causes, and fixing solutions from the code snippets."
  },
  {
    "file_name": "LLM4Vuln_ A Unified Evaluation Framework for Decoupling and Enhancing LLMs' Vulnerability Reasoning.pdf",
    "bug_type": "The bug types include vulnerabilities in Solidity, Java, and C/C++. The vulnerabilities are a mix of real-world vulnerabilities (e.g., those found in actual projects) and synthetic vulnerabilities (e.g., those created for testing purposes).",
    "bug_origin": "Real-world",
    "programming_language": "The programming languages used are Solidity, Java, and C/C++.",
    "benchmarks_or_datasets": "The datasets include:",
    "dataset_tool_repo": "Yes, the code and all raw evaluation data are released on an anonymous website, but the specific link is not provided in the text.",
    "publicly_available": "No",
    "llm_prompt_strategy": "Yes, the paper discusses the use of prompt strategies, including:"
  },
  {
    "file_name": "ANVIL_ Anomaly-based Vulnerability Identification without Labelled Training Data.pdf",
    "bug_type": "The bug type discussed in the paper is related to vulnerabilities in code. The vulnerabilities are real-world, as the evaluation is conducted on datasets containing real-world vulnerabilities (e.g., CVEs).",
    "bug_origin": "Real-world",
    "programming_language": "The programming languages used in the experiments are C and C++.",
    "benchmarks_or_datasets": "The benchmarks/datasets used include:",
    "dataset_tool_repo": "Yes, the dataset is publicly available in the repository created by the authors to support future research. However, the specific link is not provided in the context.",
    "publicly_available": "Yes",
    "llm_prompt_strategy": ""
  }
]
